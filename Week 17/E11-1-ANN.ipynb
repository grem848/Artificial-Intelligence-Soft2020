{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random as ran\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Andreas Heick Laptop\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\compat\\v2_compat.py:65: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.datasets.mnist as mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test plot to see an image\n",
    "def display_digit(num):\n",
    "    print(y_train[num])\n",
    "    label = y_train[num].argmax(axis=0)\n",
    "    image = X_train[num].reshape([28,28])\n",
    "    plt.title('Example: %d  Label: %d' % (num, label))\n",
    "    plt.imshow(image, cmap=plt.get_cmap('gray_r'))\n",
    "    plt.grid()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_digit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train/255\n",
    "X_test = X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
       "        0.07058824, 0.49411765, 0.53333333, 0.68627451, 0.10196078,\n",
       "        0.65098039, 1.        , 0.96862745, 0.49803922, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.11764706, 0.14117647,\n",
       "        0.36862745, 0.60392157, 0.66666667, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.88235294, 0.6745098 ,\n",
       "        0.99215686, 0.94901961, 0.76470588, 0.25098039, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.19215686, 0.93333333, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.98431373, 0.36470588, 0.32156863,\n",
       "        0.32156863, 0.21960784, 0.15294118, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.07058824, 0.85882353, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.77647059,\n",
       "        0.71372549, 0.96862745, 0.94509804, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.31372549, 0.61176471,\n",
       "        0.41960784, 0.99215686, 0.99215686, 0.80392157, 0.04313725,\n",
       "        0.        , 0.16862745, 0.60392157, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
       "        0.00392157, 0.60392157, 0.99215686, 0.35294118, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.54509804, 0.99215686, 0.74509804, 0.00784314,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.04313725, 0.74509804, 0.99215686, 0.2745098 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.1372549 , 0.94509804, 0.88235294,\n",
       "        0.62745098, 0.42352941, 0.00392157, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.31764706, 0.94117647,\n",
       "        0.99215686, 0.99215686, 0.46666667, 0.09803922, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.17647059,\n",
       "        0.72941176, 0.99215686, 0.99215686, 0.58823529, 0.10588235,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.0627451 , 0.36470588, 0.98823529, 0.99215686, 0.73333333,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.97647059, 0.99215686, 0.97647059,\n",
       "        0.25098039, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.18039216,\n",
       "        0.50980392, 0.71764706, 0.99215686, 0.99215686, 0.81176471,\n",
       "        0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.15294118, 0.58039216, 0.89803922,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.98039216, 0.71372549,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.09411765, 0.44705882, 0.86666667, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.78823529, 0.30588235, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.09019608, 0.25882353,\n",
       "        0.83529412, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.77647059, 0.31764706, 0.00784314, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.07058824, 0.67058824, 0.85882353, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.76470588, 0.31372549,\n",
       "        0.03529412, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.21568627,\n",
       "        0.6745098 , 0.88627451, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.95686275, 0.52156863, 0.04313725, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.53333333,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.83137255, 0.52941176,\n",
       "        0.51764706, 0.0627451 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatter(matrix):\n",
    "    return [item for row in matrix for item in row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vector = [flatter(image) for image in X_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_vector = [flatter(image) for image in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.050980392156862744,\n",
       " 0.09803921568627451,\n",
       " 0.39215686274509803,\n",
       " 0.47843137254901963,\n",
       " 0.027450980392156862,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.12941176470588237,\n",
       " 0.592156862745098,\n",
       " 0.8156862745098039,\n",
       " 0.9882352941176471,\n",
       " 0.9882352941176471,\n",
       " 0.9882352941176471,\n",
       " 0.5725490196078431,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.1568627450980392,\n",
       " 0.596078431372549,\n",
       " 0.9568627450980393,\n",
       " 0.9882352941176471,\n",
       " 0.9921568627450981,\n",
       " 0.8784313725490196,\n",
       " 0.8274509803921568,\n",
       " 0.9882352941176471,\n",
       " 0.9098039215686274,\n",
       " 0.1568627450980392,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.058823529411764705,\n",
       " 0.596078431372549,\n",
       " 0.9372549019607843,\n",
       " 0.9882352941176471,\n",
       " 0.9882352941176471,\n",
       " 0.9882352941176471,\n",
       " 0.8470588235294118,\n",
       " 0.12156862745098039,\n",
       " 0.1450980392156863,\n",
       " 0.9882352941176471,\n",
       " 0.9882352941176471,\n",
       " 0.23529411764705882,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.3764705882352941,\n",
       " 0.9882352941176471,\n",
       " 0.9882352941176471,\n",
       " 0.9882352941176471,\n",
       " 0.9882352941176471,\n",
       " 0.8509803921568627,\n",
       " 0.11372549019607843,\n",
       " 0.0,\n",
       " 0.1450980392156863,\n",
       " 0.9882352941176471,\n",
       " 0.9882352941176471,\n",
       " 0.23529411764705882,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.7098039215686275,\n",
       " 0.9882352941176471,\n",
       " 0.9882352941176471,\n",
       " 0.8627450980392157,\n",
       " 0.6549019607843137,\n",
       " 0.11764705882352941,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.30196078431372547,\n",
       " 0.9882352941176471,\n",
       " 0.9882352941176471,\n",
       " 0.23529411764705882,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.10196078431372549,\n",
       " 0.5019607843137255,\n",
       " 0.22745098039215686,\n",
       " 0.08627450980392157,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.39215686274509803,\n",
       " 0.9882352941176471,\n",
       " 0.9882352941176471,\n",
       " 0.23529411764705882,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.615686274509804,\n",
       " 0.9882352941176471,\n",
       " 0.9882352941176471,\n",
       " 0.23529411764705882,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.43137254901960786,\n",
       " 0.4745098039215686,\n",
       " 0.47843137254901963,\n",
       " 0.4745098039215686,\n",
       " 0.792156862745098,\n",
       " 0.9882352941176471,\n",
       " 0.7607843137254902,\n",
       " 0.011764705882352941,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0392156862745098,\n",
       " 0.20784313725490197,\n",
       " 0.7019607843137254,\n",
       " 0.9921568627450981,\n",
       " 0.9921568627450981,\n",
       " 1.0,\n",
       " 0.9921568627450981,\n",
       " 0.9921568627450981,\n",
       " 0.8941176470588236,\n",
       " 0.13725490196078433,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0196078431372549,\n",
       " 0.21176470588235294,\n",
       " 0.8901960784313725,\n",
       " 0.9882352941176471,\n",
       " 0.9529411764705882,\n",
       " 0.8941176470588236,\n",
       " 0.6666666666666666,\n",
       " 0.9490196078431372,\n",
       " 0.9882352941176471,\n",
       " 0.9882352941176471,\n",
       " 0.9058823529411765,\n",
       " 0.4588235294117647,\n",
       " 0.023529411764705882,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.023529411764705882,\n",
       " 0.3058823529411765,\n",
       " 0.9882352941176471,\n",
       " 0.9882352941176471,\n",
       " 0.49019607843137253,\n",
       " 0.23137254901960785,\n",
       " 0.0,\n",
       " 0.07058823529411765,\n",
       " 0.8156862745098039,\n",
       " 0.9882352941176471,\n",
       " 0.9882352941176471,\n",
       " 0.9882352941176471,\n",
       " 0.9882352941176471,\n",
       " 0.3411764705882353,\n",
       " 0.027450980392156862,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0196078431372549,\n",
       " 0.5294117647058824,\n",
       " 0.9882352941176471,\n",
       " 0.9882352941176471,\n",
       " 0.7058823529411765,\n",
       " 0.06274509803921569,\n",
       " 0.0,\n",
       " 0.08235294117647059,\n",
       " 0.796078431372549,\n",
       " 0.9921568627450981,\n",
       " 0.9686274509803922,\n",
       " 0.5058823529411764,\n",
       " 0.6784313725490196,\n",
       " 0.9882352941176471,\n",
       " 0.9882352941176471,\n",
       " 0.7215686274509804,\n",
       " 0.25882352941176473,\n",
       " 0.19215686274509805,\n",
       " 0.19215686274509805,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.011764705882352941,\n",
       " 0.5333333333333333,\n",
       " 0.9882352941176471,\n",
       " 0.9450980392156862,\n",
       " 0.41568627450980394,\n",
       " 0.06666666666666667,\n",
       " 0.0,\n",
       " 0.20784313725490197,\n",
       " 0.7843137254901961,\n",
       " 0.9882352941176471,\n",
       " 0.8470588235294118,\n",
       " 0.2549019607843137,\n",
       " 0.0,\n",
       " 0.054901960784313725,\n",
       " 0.2823529411764706,\n",
       " 0.6392156862745098,\n",
       " 0.9450980392156862,\n",
       " 0.9882352941176471,\n",
       " 0.9882352941176471,\n",
       " 0.8745098039215686,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.4117647058823529,\n",
       " 0.9882352941176471,\n",
       " 0.9490196078431372,\n",
       " 0.34509803921568627,\n",
       " 0.07058823529411765,\n",
       " 0.28627450980392155,\n",
       " 0.6666666666666666,\n",
       " 0.9568627450980393,\n",
       " 0.9882352941176471,\n",
       " 0.49411764705882355,\n",
       " 0.11372549019607843,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.34901960784313724,\n",
       " 0.7058823529411765,\n",
       " 0.7058823529411765,\n",
       " 0.1450980392156863,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.9058823529411765,\n",
       " 0.9882352941176471,\n",
       " 0.9607843137254902,\n",
       " 0.803921568627451,\n",
       " 0.8470588235294118,\n",
       " 0.9882352941176471,\n",
       " 0.9882352941176471,\n",
       " 0.9882352941176471,\n",
       " 0.48627450980392156,\n",
       " 0.011764705882352941,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.8117647058823529,\n",
       " 0.9882352941176471,\n",
       " 0.9882352941176471,\n",
       " 0.9882352941176471,\n",
       " 0.9882352941176471,\n",
       " 0.6980392156862745,\n",
       " 0.4549019607843137,\n",
       " 0.1411764705882353,\n",
       " 0.01568627450980392,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.050980392156862744,\n",
       " 0.36470588235294116,\n",
       " 0.5607843137254902,\n",
       " 0.4745098039215686,\n",
       " 0.09019607843137255,\n",
       " 0.023529411764705882,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vector[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_vector = np.zeros((y_train.size,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_vector = np.zeros((y_test.size,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, j in enumerate(y_train_vector):\n",
    "    j[y_train[i]] = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_vector[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n1 = X_train.shape[0]\n",
    "n1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n2 = X_test.shape[0]\n",
    "n2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 100\n",
    "batch_num = n1/batch_size\n",
    "batch_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the layers\n",
    "input_layer = 784\n",
    "nodes_hl1 = 512\n",
    "nodes_hl2 = 256\n",
    "nodes_hl3 = 128\n",
    "output_layer = 10\n",
    "\n",
    "classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "l_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topo(x):\n",
    "    hl1 = {'w1':tf.Variable(tf.random_normal(input_layer, nodes_hl1)), 'b1':tf.Variable(tf.random_normal(nodes_hl1))}\n",
    "    hl2 = {'w2':tf.Variable(tf.random_normal(hl1, nodes_hl2)), 'b2':tf.Variable(tf.random_normal(nodes_hl2))}\n",
    "    hl3 = {'w3':tf.Variable(tf.random_normal(hl2, nodes_hl3)), 'b3':tf.Variable(tf.random_normal(nodes_hl3))}\n",
    "    output_layer = {'w':tf.Variable(tf.random_normal(hl3, classes)), 'b':tf.Variable(tf.random_normal(classes))}\n",
    "    \n",
    "    l1 = tf.matmul(x, hl1['w1'])\n",
    "    l1 = tf.add(l1, hl1['b1'])\n",
    "    l1 =  tf.nn.relu(l1)\n",
    "    \n",
    "    l2 = tf.nn.relu(tf.add(tf.matmul(hl1, hl2['w2']), hl2['b2']))\n",
    "    \n",
    "    l3 = tf.nn.relu(tf.add(tf.matmul(hl2, hl3['w3']), hl3['b3']))\n",
    "    \n",
    "    out = tf.matmul(l3, output_layer['w']) + output_layer['b']\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder('float', [None, 784])\n",
    "y = tf.placeholder('float', [None, 10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation function - will be used during the training\n",
    "def validate(predicted, expected):\n",
    "    correct = tf.equal(tf.argmax(predicted, 1), tf.argmax(expected, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n",
    "    print('Accuracy:',accuracy.eval({x:X_test_vector, y:y_test_vector}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn(x):\n",
    "    print(x)\n",
    "    # Start iteration of prediction using the computation graph above\n",
    "    prediction = topo(x)\n",
    "    # estimate the error/cost/loss \n",
    "    # based on the probability that the classes are mutually exclusive, so labels are informative\n",
    "    cost = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits_v2(logits=prediction, labels=y) )\n",
    "    # cost has the value we try to minimize by manipulating the weights\n",
    "    # minimise the cost by optimization function\n",
    "    optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "    # Create session    \n",
    "    with tf.Session() as sess:\n",
    "        # initialize the variables we created\n",
    "        sess.run(tf.global_variables_initializer())        \n",
    "        # start iterations for each epoch\n",
    "        for epoch in range(epochs):\n",
    "            epoch_loss = 0\n",
    "            i=0\n",
    "            # same for each batch (partition of our data)\n",
    "            while i < 10:\n",
    "                start = i\n",
    "                end = i+batch_size\n",
    "                # get the next batch of random data\n",
    "                epoch_x = np.array(X_train_vector[start:end])\n",
    "                epoch_y = np.array(y_train_vector[start:end])\n",
    "                # feeding the placeholders for x and y\n",
    "                _, c = sess.run([optimizer, cost], feed_dict={x: epoch_x, y: epoch_y})\n",
    "                epoch_loss += c\n",
    "                i+=batch_size\n",
    "                \n",
    "            #Validate the accuracy\n",
    "            validate(prediction, y)\n",
    "\n",
    "            #Validate the accuracy\n",
    "            validate(prediction, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder_8:0\", shape=(?, 784), dtype=float32)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shape must be rank 1 but is rank 0 for 'random_normal_2/RandomStandardNormal' (op: 'RandomStandardNormal') with input shapes: [].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1610\u001b[1;33m     \u001b[0mc_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1611\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Shape must be rank 1 but is rank 0 for 'random_normal_2/RandomStandardNormal' (op: 'RandomStandardNormal') with input shapes: [].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-aea230416861>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_nn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-38-1c146fa919ea>\u001b[0m in \u001b[0;36mtrain_nn\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;31m# Start iteration of prediction using the computation graph above\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtopo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;31m# estimate the error/cost/loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m# based on the probability that the classes are mutually exclusive, so labels are informative\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-25-12f93c672179>\u001b[0m in \u001b[0;36mtopo\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtopo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mhl1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'w1'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_normal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_layer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnodes_hl1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'b1'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_normal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnodes_hl1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mhl2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'w2'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_normal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhl1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnodes_hl2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'b2'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_normal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnodes_hl2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mhl3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'w3'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_normal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhl2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnodes_hl3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'b3'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_normal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnodes_hl3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0moutput_layer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'w'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_normal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhl3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'b'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_normal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\random_ops.py\u001b[0m in \u001b[0;36mrandom_normal\u001b[1;34m(shape, mean, stddev, dtype, seed, name)\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[0mseed1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_seed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m     rnd = gen_random_ops.random_standard_normal(\n\u001b[1;32m---> 74\u001b[1;33m         shape_tensor, dtype, seed=seed1, seed2=seed2)\n\u001b[0m\u001b[0;32m     75\u001b[0m     \u001b[0mmul\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnd\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mstddev_tensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmul\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_random_ops.py\u001b[0m in \u001b[0;36mrandom_standard_normal\u001b[1;34m(shape, dtype, seed, seed2, name)\u001b[0m\n\u001b[0;32m    727\u001b[0m   _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[0;32m    728\u001b[0m         \u001b[1;34m\"RandomStandardNormal\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 729\u001b[1;33m                                 seed2=seed2, name=name)\n\u001b[0m\u001b[0;32m    730\u001b[0m   \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    731\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    791\u001b[0m         op = g.create_op(op_type_name, inputs, dtypes=None, name=scope,\n\u001b[0;32m    792\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 793\u001b[1;33m                          op_def=op_def)\n\u001b[0m\u001b[0;32m    794\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    795\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    505\u001b[0m                 \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m                 instructions)\n\u001b[1;32m--> 507\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    508\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   3358\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Input #%d is not a tensor: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3359\u001b[0m     return self._create_op_internal(op_type, inputs, dtypes, input_types, name,\n\u001b[1;32m-> 3360\u001b[1;33m                                     attrs, op_def, compute_device)\n\u001b[0m\u001b[0;32m   3361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3362\u001b[0m   def _create_op_internal(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m   3427\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3428\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3429\u001b[1;33m           op_def=op_def)\n\u001b[0m\u001b[0;32m   3430\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3431\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   1771\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[0;32m   1772\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[1;32m-> 1773\u001b[1;33m                                 control_input_ops)\n\u001b[0m\u001b[0;32m   1774\u001b[0m     \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1775\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[0;32m   1611\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1612\u001b[0m     \u001b[1;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1613\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1614\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1615\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Shape must be rank 1 but is rank 0 for 'random_normal_2/RandomStandardNormal' (op: 'RandomStandardNormal') with input shapes: []."
     ]
    }
   ],
   "source": [
    "train_nn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
